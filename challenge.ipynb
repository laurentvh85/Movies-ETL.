{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "from config import db_password\n",
    "import psycopg2\n",
    "import time\n",
    "\n",
    "#file directory variable\n",
    "file_dir = '/Users/laurentvanhassel/Desktop/classwork/Module8/Movies-ETL./'\n",
    "\n",
    "# wiki_movies_raw variable\n",
    "# Open and load Wikepedia JSON\n",
    "with open(f'{file_dir}/wikipedia.movies.json', mode='r') as file:\n",
    "    wiki_movies_raw = json.load(file)\n",
    "\n",
    "# Read Kaggle metadata and ratings\n",
    "kaggle_metadata = pd.read_csv(f'{file_dir}movies_metadata.csv')\n",
    "ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
    "\n",
    "def ETL(wiki_movies_raw, kaggle_metadata, ratings):\n",
    "#set wikipedia parameters \n",
    "    try:\n",
    "        wiki_movies = [movie for movie in wiki_movies_raw\n",
    "                  if ('Director' in movie or 'Directed by' in movie) and 'imdb_link' in movie and 'No. of episodes' not in movie]\n",
    "        #Clean wikipedia data\n",
    "        def clean_movie(movie):\n",
    "            movie = dict(movie) #create a non-destructive copy\n",
    "            alt_titles = {}\n",
    "            # combine alternate titles into one list\n",
    "            for key in ['Also known as','Arabic','Cantonese',\n",
    "                        'Chinese','French','Hangul','Hebrew',\n",
    "                        'Hepburn','Japanese','Literally','Mandarin',\n",
    "                        'McCune–Reischauer','Original title','Polish',\n",
    "                        'Revised Romanization','Romanized','Russian',\n",
    "                        'Simplified','Traditional','Yiddish']:\n",
    "                if key in movie:\n",
    "                    alt_titles[key] = movie[key]\n",
    "                    movie.pop(key)\n",
    "            if len(alt_titles) > 0:\n",
    "                movie['alt_titles'] = alt_titles\n",
    "# merge column names\n",
    "            def change_column_name(old_name, new_name):\n",
    "                if old_name in movie:\n",
    "                    movie[new_name] = movie.pop(old_name)\n",
    "            change_column_name('Adaptation by', 'Writer(s)')\n",
    "            change_column_name('Country of origin', 'Country')\n",
    "            change_column_name('Directed by', 'Director')\n",
    "            change_column_name('Distributed by', 'Distributor')\n",
    "            change_column_name('Edited by', 'Editor(s)')\n",
    "            change_column_name('Length', 'Running time')\n",
    "            change_column_name('Original release', 'Release date')\n",
    "            change_column_name('Music by', 'Composer(s)')\n",
    "            change_column_name('Produced by', 'Producer(s)')\n",
    "            change_column_name('Producer', 'Producer(s)')\n",
    "            change_column_name('Productioncompanies ', 'Production company(s)')\n",
    "            change_column_name('Productioncompany ', 'Production company(s)')\n",
    "            change_column_name('Released', 'Release Date')\n",
    "            change_column_name('Release Date', 'Release date')\n",
    "            change_column_name('Screen story by', 'Writer(s)')\n",
    "            change_column_name('Screenplay by', 'Writer(s)')\n",
    "            change_column_name('Story by', 'Writer(s)')\n",
    "            change_column_name('Theme music composer', 'Composer(s)')\n",
    "            change_column_name('Written by', 'Writer(s)')\n",
    "\n",
    "            return movie\n",
    "        #convert wiki into DF \n",
    "        clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
    "        wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "\n",
    "        #Find imdb and drop duplicates\n",
    "        wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
    "        wiki_movies_df.drop_duplicates(subset='imdb_id',inplace=True)\n",
    "\n",
    "        #clean the collumns  \n",
    "        wiki_columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df)*0.9]\n",
    "        wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]\n",
    "\n",
    "        #box office variable\n",
    "        box_office = wiki_movies_df['Box office'].dropna()\n",
    "        box_office = box_office.apply(lambda x: ''.join(x) if type(x) == list else x)\n",
    "\n",
    "        form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illi?on'\n",
    "        form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'\n",
    "        box_office = box_office.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "\n",
    "        #Extract box office that match form_one or form_two\n",
    "        box_office.str.extract(f'({form_one}|{form_two})')\n",
    "\n",
    "    #Create a function to parse the dollars values and create the correct format for them.\n",
    "        def parse_dollars(s):\n",
    "            # if s is not a string, return NaN\n",
    "            if type(s) != str:\n",
    "                return np.nan\n",
    "\n",
    "            # if input is of the form $###.# million\n",
    "            if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "                # remove dollar sign and \" million\"\n",
    "                s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "                # convert to float and multiply by a million\n",
    "                value = float(s) * 10**6\n",
    "\n",
    "                # return value\n",
    "                return value\n",
    "\n",
    "            # if input is of the form $###.# billion\n",
    "            elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "                # remove dollar sign and \" billion\"\n",
    "                s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "                # convert to float and multiply by a billion\n",
    "                value = float(s) * 10**9\n",
    "\n",
    "                # return value\n",
    "                return value\n",
    "\n",
    "            # if input is of the form $###,###,###\n",
    "            elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
    "\n",
    "                # remove dollar sign and commas\n",
    "                s = re.sub('\\$|,','', s)\n",
    "\n",
    "                # convert to float\n",
    "                value = float(s)\n",
    "\n",
    "                # return value\n",
    "                return value\n",
    "\n",
    "            # otherwise, return NaN\n",
    "            else:\n",
    "                return np.nan\n",
    "\n",
    "        #parse_dollars function box_office\n",
    "        wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "\n",
    "        #Drop \"Box office\" from DF\n",
    "        wiki_movies_df.drop('Box office', axis=1, inplace=True)\n",
    "\n",
    "        #variable to drop movies sans budget\n",
    "        budget = wiki_movies_df['Budget'].dropna()\n",
    "\n",
    "        #Join lists\n",
    "        budget = budget.map(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "        budget = budget.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "\n",
    "        #Remove citation\n",
    "        budget = budget.str.replace(r'\\[\\d+\\]\\s*', '')\n",
    "\n",
    "        #Extract budgets that match\n",
    "        wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "\n",
    "        #Remove duplicate budget from df\n",
    "        wiki_movies_df.drop('Budget', axis=1, inplace=True)\n",
    "\n",
    "        #Create release_date variable\n",
    "        release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "\n",
    "        #date form variables\n",
    "        date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]\\d,\\s\\d{4}'\n",
    "        date_form_two = r'\\d{4}.[01]\\d.[123]\\d'\n",
    "        date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
    "        date_form_four = r'\\d{4}'\n",
    "\n",
    "        #match releasedate formula\n",
    "        wiki_movies_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0], infer_datetime_format=True)\n",
    "\n",
    "        #run time variable\n",
    "        running_time = wiki_movies_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "\n",
    "        #extract our format\n",
    "        running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
    "\n",
    "        #Convert run time to numeric\n",
    "        running_time_extract = running_time_extract.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
    "\n",
    "        wiki_movies_df['running_time'] = running_time_extract.apply(lambda row: row[0]*60 + row[1] if row[2] == 0 else row[2], axis=1)\n",
    "\n",
    "        #drop dupe\n",
    "        wiki_movies_df.drop('Running time', axis=1, inplace=True)\n",
    "\n",
    "        #Merge wiki & kaggle dfs \n",
    "        movies_df = pd.merge(wiki_movies_df, kaggle_metadata, on='imdb_id', suffixes=['_wiki','_kaggle'])\n",
    "    except:\n",
    "        print(\"error: issue with wiki_movies_raw file. verify that the correct path is set.\")\n",
    "\n",
    "    #Transform Kaggle Data \n",
    "    try:\n",
    "        #kaggle data where the adult column is equal to \"False\"\n",
    "        kaggle_metadata = kaggle_metadata[kaggle_metadata['adult'] == 'FALSE'].drop('adult',axis='columns')\n",
    "\n",
    "        #kaggle 'video' column is true\n",
    "        kaggle_metadata['video'] = kaggle_metadata['video'] == 'True'\n",
    "\n",
    "        #Convert budget, id, and popularity to proper datatypes\n",
    "        kaggle_metadata['budget'] = kaggle_metadata['budget'].astype(int)\n",
    "        kaggle_metadata['id'] = pd.to_numeric(kaggle_metadata['id'], errors='raise')\n",
    "        kaggle_metadata['popularity'] = pd.to_numeric(kaggle_metadata['popularity'], errors='raise')\n",
    "\n",
    "        #Convert 'release_date' to proper format\n",
    "        kaggle_metadata['release_date'] = pd.to_datetime(kaggle_metadata['release_date'])\n",
    "\n",
    "        movies_df = movies_df.drop(movies_df[(movies_df['release_date_wiki'] > '1996-01-01') & (movies_df['release_date_kaggle'] < '1965-01-01')].index)\n",
    "\n",
    "        #Drop certain comllumns\n",
    "        movies_df.drop(columns=['title_wiki','release_date_wiki','Language','Production company(s)'], inplace=True)\n",
    "\n",
    "        #Fill in missing data, then remove dupes\n",
    "        def fill_missing_kaggle_data(df, kaggle_column, wiki_column):\n",
    "            df[kaggle_column] = df.apply(\n",
    "                lambda row: row[wiki_column] if row[kaggle_column] == 0 else row[kaggle_column], axis=1)\n",
    "            df.drop(columns=wiki_column, inplace=True)\n",
    "\n",
    "        #Fill in missing data, then remove dupes\n",
    "        fill_missing_kaggle_data(movies_df, 'runtime', 'running_time')\n",
    "        fill_missing_kaggle_data(movies_df, 'budget_kaggle', 'budget_wiki')\n",
    "        fill_missing_kaggle_data(movies_df, 'revenue', 'box_office')\n",
    "\n",
    "        #create proper DF\n",
    "        movies_df = movies_df.loc[:, ['imdb_id','id','title_kaggle','original_title',\n",
    "                                      'tagline','belongs_to_collection','url','imdb_link',\n",
    "                                      'runtime','budget_kaggle','revenue','release_date_kaggle',\n",
    "                                      'popularity','vote_average','vote_count','genres',\n",
    "                                      'original_language','overview','spoken_languages',\n",
    "                                      'Country','production_companies','production_countries',\n",
    "                                      'Distributor','Producer(s)','Director','Starring',\n",
    "                                      'Cinematography','Editor(s)','Writer(s)','Composer(s)','Based on']]\n",
    "\n",
    "        #format names for DF\n",
    "        movies_df.rename({'id':'kaggle_id','title_kaggle':'title',\n",
    "                          'url':'wikipedia_url','budget_kaggle':'budget',\n",
    "                          'release_date_kaggle':'release_date','Country':'country',\n",
    "                          'Distributor':'distributor','Producer(s)':'producers',\n",
    "                          'Director':'director','Starring':'starring',\n",
    "                          'Cinematography':'cinematography','Editor(s)':'editors',\n",
    "                          'Writer(s)':'writers','Composer(s)':'composers',\n",
    "                          'Based on':'based_on'}, axis='columns', inplace=True)\n",
    "    except:\n",
    "        print(\"error: Issue with the'kaggle_metadata' file. verify that the correct path is set\")\n",
    "    #convert the timestamp column of the ratings data to datetime\n",
    "    try: \n",
    "        ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "\n",
    "        rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count() \\\n",
    "                        .rename({'userId':'count'}, axis=1) \\\n",
    "                        .pivot(index='movieId',columns='rating', values='count')\n",
    "        #Rename the columns\n",
    "        rating_counts.columns = ['rating_' + str(col) for col in rating_counts.columns]\n",
    "\n",
    "        #convert \"kaggle_id\" datatype \n",
    "        movies_df[\"kaggle_id\"]=movies_df[\"kaggle_id\"].astype(int)\n",
    "\n",
    "        #Merge ratings with movies dataframe\n",
    "        movies_with_ratings_df = pd.merge(movies_df, rating_counts, left_on='kaggle_id', right_index=True, how='left')\n",
    "\n",
    "        #fill NaN values for rating counts with 0.\n",
    "        movies_with_ratings_df[rating_counts.columns] = movies_with_ratings_df[rating_counts.columns].fillna(0)\n",
    "    except: \n",
    "        print(\"error: Issue with the'ratings' file. verify that the correct path is set\")\n",
    "\n",
    "#upload data to SQL\n",
    "    #SQL Connection\n",
    "    db_string = f\"postgres://postgres:{db_password}@127.0.0.1:5432/movie_data\"\n",
    "\n",
    "    #database engine\n",
    "    engine = create_engine(db_string)\n",
    "         \n",
    "    try:\n",
    "        movies_df.to_sql(name='movies', con=engine)\n",
    "       #If error print out text\n",
    "    except:\n",
    "       print(\"error: if movie_data has been created, then clear movies table in SQL before attempting to run script\")\n",
    "       \n",
    "    #Export ratings data SQL\n",
    "    rows_imported = 0\n",
    "    # get the start_time from time.time()\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        for data in pd.read_csv(f'{file_dir}/ratings.csv', chunksize=1000000):\n",
    "            print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "            data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "            rows_imported += len(data)\n",
    "            # add elapsed time\n",
    "            print(f'Done. {time.time() - start_time} total seconds elapsed')\n",
    "    except:\n",
    "        #If error print out text\n",
    "        print(\"\\nerror: make sure movie_data is created in PGAdmin\") \n",
    "        \n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 0 to 1000000...Done. 73.75511503219604 total seconds elapsed\n",
      "importing rows 1000000 to 2000000...Done. 161.8793351650238 total seconds elapsed\n",
      "importing rows 2000000 to 3000000...Done. 263.31561493873596 total seconds elapsed\n",
      "importing rows 3000000 to 4000000...Done. 377.7841031551361 total seconds elapsed\n",
      "importing rows 4000000 to 5000000..."
     ]
    }
   ],
   "source": [
    "ETL(wiki_movies_raw, kaggle_metadata, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
